{
    "contents" : "# File-Name:       email_classify.R           \n# Date:            2012-02-10                                \n# Author:          Drew Conway (drew.conway@nyu.edu)\n# Purpose:         Code for Chapter 3. In this case we introduce the notion of binary classification.\n#                   In machine learning this is a method for determining what of two categories a \n#                   given observation belongs to.  To show this, we will create a simple naive Bayes \n#                   classifier for SPAM email detection, and visualize the results.\n# Data Used:       Email messages contained in data/ directory, source: http://spamassassin.apache.org/publiccorpus/\n# Packages Used:   tm, ggplot2\n\n# All source code is copyright (c) 2012, under the Simplified BSD License.  \n# For more information on FreeBSD see: http://www.opensource.org/licenses/bsd-license.php\n\n# All images and materials produced by this code are licensed under the Creative Commons \n# Attribution-Share Alike 3.0 United States License: http://creativecommons.org/licenses/by-sa/3.0/us/\n\n# All rights reserved.\n\n# NOTE: If you are running this in the R console you must use the 'setwd' command to set the \n# working directory for the console to whereever you have saved this file prior to running.\n# Otherwise you will see errors when loading data or saving figures!\n\n# Load libraries\nlibrary('tm')\nlibrary('ggplot2')\n\n# Set the global paths\nspam.path <- file.path(\"data\", \"spam\")\nspam2.path <- file.path(\"data\", \"spam_2\")\neasyham.path <- file.path(\"data\", \"easy_ham\")\neasyham2.path <- file.path(\"data\", \"easy_ham_2\")\nhardham.path <- file.path(\"data\", \"hard_ham\")\nhardham2.path <- file.path(\"data\", \"hard_ham_2\")\n\n# Create motivating plot\nx <- runif(1000, 0, 40)\ny1 <- cbind(runif(100, 0, 10), 1)\ny2 <- cbind(runif(800, 10, 30), 2)\ny3 <- cbind(runif(100, 30, 40), 1)\n\nval <- data.frame(cbind(x, rbind(y1, y2, y3)),\n                  stringsAsFactors = TRUE)\n\nex1 <- ggplot(val, aes(x, V2)) +\n  geom_jitter(aes(shape = as.factor(V3)),\n                  position = position_jitter(height = 2)) +\n  scale_shape_discrete(legend = FALSE, solid = FALSE) +\n  geom_hline(aes(yintercept = c(10,30), linetype = 2)) +\n  theme_bw() +\n  xlab(\"X\") +\n  ylab(\"Y\")\nggsave(plot = ex1,\n       filename = file.path(\"images\", \"00_Ex1.pdf\"),\n       height = 10,\n       width = 10)\n\n# Return a single element vector of just the email body\n# This is a very simple approach, as we are only using \n# words as features\nget.msg <- function(path)\n{\n  con <- file(path, open = \"rt\", encoding = \"latin1\")\n  text <- readLines(con)\n  # The message always begins after the first full line break\n  msg <- text[seq(which(text == \"\")[1] + 1, length(text), 1)]\n  close(con)\n  return(paste(msg, collapse = \"\\n\"))\n}\n\n# Create a TermDocumentMatrix (TDM) from the corpus of SPAM email.\n# The TDM control can be modified, and the sparsity level can be \n# altered.  This TDM is used to create the feature set used to do \n# train our classifier.\nget.tdm <- function(doc.vec)\n{\n  control <- list(stopwords = TRUE,\n                  removePunctuation = TRUE,\n                  removeNumbers = TRUE,\n                  minDocFreq = 2)\n  doc.corpus <- Corpus(VectorSource(doc.vec))\n  doc.dtm <- TermDocumentMatrix(doc.corpus, control)\n  return(doc.dtm)\n}\n\n# This function takes a file path to an email file and a string, \n# the term parameter, and returns the count of that term in \n# the email body.\ncount.word <- function(path, term)\n{\n  msg <- get.msg(path)\n  msg.corpus <- Corpus(VectorSource(msg))\n  # Hard-coded TDM control\n  control <- list(stopwords = TRUE,\n                  removePunctuation = TRUE,\n                  removeNumbers = TRUE)\n  msg.tdm <- TermDocumentMatrix(msg.corpus, control)\n  word.freq <- rowSums(as.matrix(msg.tdm))\n  term.freq <- word.freq[which(names(word.freq) == term)]\n  # We use ifelse here because term.freq = NA if nothing is found\n  return(ifelse(length(term.freq) > 0, term.freq, 0))\n}\n\n# This is the our workhorse function for classifying email.  It takes \n# two required paramters: a file path to an email to classify, and\n# a data frame of the trained data.  The function also takes two \n# optional parameters.  First, a prior over the probability that an email\n# is SPAM, which we set to 0.5 (naive), and constant value for the\n# probability on words in the email that are not in our training data.\n# The function returns the naive Bayes probability that the given email\n# is SPAM.  \nclassify.email <- function(path, training.df, prior = 0.5, c = 1e-6)\n{\n  # Here, we use many of the support functions to get the\n  # email text data in a workable format\n  msg <- get.msg(path)\n  msg.tdm <- get.tdm(msg)\n  msg.freq <- rowSums(as.matrix(msg.tdm))\n  # Find intersections of words\n  msg.match <- intersect(names(msg.freq), training.df$term)\n  # Now, we just perform the naive Bayes calculation\n  if(length(msg.match) < 1)\n  {\n    return(prior * c ^ (length(msg.freq)))\n  }\n  else\n  {\n    match.probs <- training.df$occurrence[match(msg.match, training.df$term)]\n    return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))\n  }\n}\n\n\n# With all of our support functions written, we can perform the classification.\n# First, we create document corpus for spam messages\n\n# Get all the SPAM-y email into a single vector\nspam.docs <- dir(spam.path)\nspam.docs <- spam.docs[which(spam.docs != \"cmds\")]\nall.spam <- sapply(spam.docs,\n                   function(p) get.msg(file.path(spam.path, p)))\n\n# Create a DocumentTermMatrix from that vector\nspam.tdm <- get.tdm(all.spam)\n\n# Create a data frame that provides the feature set from the training SPAM data\nspam.matrix <- as.matrix(spam.tdm)\nspam.counts <- rowSums(spam.matrix)\nspam.df <- data.frame(cbind(names(spam.counts),\n                            as.numeric(spam.counts)),\n                      stringsAsFactors = FALSE)\nnames(spam.df) <- c(\"term\", \"frequency\")\nspam.df$frequency <- as.numeric(spam.df$frequency)\nspam.occurrence <- sapply(1:nrow(spam.matrix),\n                          function(i)\n                          {\n                            length(which(spam.matrix[i, ] > 0)) / ncol(spam.matrix)\n                          })\nspam.density <- spam.df$frequency / sum(spam.df$frequency)\n\n# Add the term density and occurrence rate\nspam.df <- transform(spam.df,\n                     density = spam.density,\n                     occurrence = spam.occurrence)\n\n# Now do the same for the EASY HAM email\neasyham.docs <- dir(easyham.path)\neasyham.docs <- easyham.docs[which(easyham.docs != \"cmds\")]\nall.easyham <- sapply(easyham.docs[1:length(spam.docs)],\n                      function(p) get.msg(file.path(easyham.path, p)))\n\neasyham.tdm <- get.tdm(all.easyham)\n\neasyham.matrix <- as.matrix(easyham.tdm)\neasyham.counts <- rowSums(easyham.matrix)\neasyham.df <- data.frame(cbind(names(easyham.counts),\n                               as.numeric(easyham.counts)),\n                         stringsAsFactors = FALSE)\nnames(easyham.df) <- c(\"term\", \"frequency\")\neasyham.df$frequency <- as.numeric(easyham.df$frequency)\neasyham.occurrence <- sapply(1:nrow(easyham.matrix),\n                            function(i)\n                            {\n                              length(which(easyham.matrix[i, ] > 0)) / ncol(easyham.matrix)\n                            })\neasyham.density <- easyham.df$frequency / sum(easyham.df$frequency)\n\neasyham.df <- transform(easyham.df,\n                        density = easyham.density,\n                        occurrence = easyham.occurrence)\n\n# Run classifer against HARD HAM\nhardham.docs <- dir(hardham.path)\nhardham.docs <- hardham.docs[which(hardham.docs != \"cmds\")]\n\nhardham.spamtest <- sapply(hardham.docs,\n                           function(p) classify.email(file.path(hardham.path, p), training.df = spam.df))\n    \nhardham.hamtest <- sapply(hardham.docs,\n                          function(p) classify.email(file.path(hardham.path, p), training.df = easyham.df))\n    \nhardham.res <- ifelse(hardham.spamtest > hardham.hamtest,\n                      TRUE,\n                      FALSE)\nsummary(hardham.res)\n\n# Find counts of just terms 'html' and 'table' in all SPAM and EASYHAM docs, and create figure\nhtml.spam <- sapply(spam.docs,\n                    function(p) count.word(file.path(spam.path, p), \"html\"))\ntable.spam <- sapply(spam.docs,\n                     function(p) count.word(file.path(spam.path, p), \"table\"))\nspam.init <- cbind(html.spam, table.spam, \"SPAM\")\n\nhtml.easyham <- sapply(easyham.docs,\n                       function(p) count.word(file.path(easyham.path, p), \"html\"))\ntable.easyham <- sapply(easyham.docs,\n                        function(p) count.word(file.path(easyham.path, p), \"table\"))\neasyham.init <- cbind(html.easyham, table.easyham, \"EASYHAM\")\n\ninit.df <- data.frame(rbind(spam.init, easyham.init),\n                      stringsAsFactors = FALSE)\nnames(init.df) <- c(\"html\", \"table\", \"type\")\ninit.df$html <- as.numeric(init.df$html)\ninit.df$table <- as.numeric(init.df$table)\ninit.df$type <- as.factor(init.df$type)\n\ninit.plot1 <- ggplot(init.df, aes(x = html, y = table)) +\n  geom_point(aes(shape = type)) +\n  scale_shape_manual(values = c(\"SPAM\" = 1, \"EASYHAM\" = 3), name = \"Email Type\") +\n  xlab(\"Frequency of 'html'\") +\n  ylab(\"Freqeuncy of 'table'\") +\n  stat_abline(yintersept = 0, slope = 1) +\n  theme_bw()\nggsave(plot = init.plot1,\n       filename = file.path(\"images\", \"01_init_plot1.pdf\"),\n       width = 10,\n       height = 10)\n    \ninit.plot2 <- ggplot(init.df, aes(x = html, y = table)) +\n  geom_point(aes(shape = type), position = \"jitter\") +\n  scale_shape_manual(values = c(\"SPAM\" = 1, \"EASYHAM\" = 3), name = \"Email Type\") +\n  xlab(\"Frequency of 'html'\") +\n  ylab(\"Freqeuncy of 'table'\") +\n  stat_abline(yintersept = 0, slope = 1) +\n  theme_bw()\nggsave(plot = init.plot2,\n       filename = file.path(\"images\", \"02_init_plot2.pdf\"),\n       width = 10,\n       height = 10)\n\n# Finally, attempt to classify the HARDHAM data using the classifer developed above.\n# The rule is to classify a message as SPAM if Pr(email) = SPAM > Pr(email) = HAM\nspam.classifier <- function(path)\n{\n  pr.spam <- classify.email(path, spam.df)\n  pr.ham <- classify.email(path, easyham.df)\n  return(c(pr.spam, pr.ham, ifelse(pr.spam > pr.ham, 1, 0)))\n}\n\n# Get lists of all the email messages\neasyham2.docs <- dir(easyham2.path)\neasyham2.docs <- easyham2.docs[which(easyham2.docs != \"cmds\")]\n\nhardham2.docs <- dir(hardham2.path)\nhardham2.docs <- hardham2.docs[which(hardham2.docs != \"cmds\")]\n\nspam2.docs <- dir(spam2.path)\nspam2.docs <- spam2.docs[which(spam2.docs != \"cmds\")]\n\n# Classify them all!\neasyham2.class <- suppressWarnings(lapply(easyham2.docs,\n                                   function(p)\n                                   {\n                                     spam.classifier(file.path(easyham2.path, p))\n                                   }))\nhardham2.class <- suppressWarnings(lapply(hardham2.docs,\n                                   function(p)\n                                   {\n                                     spam.classifier(file.path(hardham2.path, p))\n                                   }))\nspam2.class <- suppressWarnings(lapply(spam2.docs,\n                                function(p)\n                                {\n                                  spam.classifier(file.path(spam2.path, p))\n                                }))\n\n# Create a single, final, data frame with all of the classification data in it\neasyham2.matrix <- do.call(rbind, easyham2.class)\neasyham2.final <- cbind(easyham2.matrix, \"EASYHAM\")\n\nhardham2.matrix <- do.call(rbind, hardham2.class)\nhardham2.final <- cbind(hardham2.matrix, \"HARDHAM\")\n\nspam2.matrix <- do.call(rbind, spam2.class)\nspam2.final <- cbind(spam2.matrix, \"SPAM\")\n\nclass.matrix <- rbind(easyham2.final, hardham2.final, spam2.final)\nclass.df <- data.frame(class.matrix, stringsAsFactors = FALSE)\nnames(class.df) <- c(\"Pr.SPAM\" ,\"Pr.HAM\", \"Class\", \"Type\")\nclass.df$Pr.SPAM <- as.numeric(class.df$Pr.SPAM)\nclass.df$Pr.HAM <- as.numeric(class.df$Pr.HAM)\nclass.df$Class <- as.logical(as.numeric(class.df$Class))\nclass.df$Type <- as.factor(class.df$Type)\n\n# Create final plot of results\nclass.plot <- ggplot(class.df, aes(x = Pr.HAM, Pr.SPAM)) +\n    geom_point(aes(shape = Type, alpha = 0.5)) +\n    stat_abline(yintercept = 0, slope = 1) +\n    scale_x_log10() +\n    scale_y_log10() +\n    scale_shape_manual(values = c(\"EASYHAM\" = 1,\n                                  \"HARDHAM\" = 2,\n                                  \"SPAM\" = 3),\n                       name = \"Email Type\") +\n    scale_alpha(legend = FALSE) +\n    xlab(\"log[Pr(HAM)]\") +\n    ylab(\"log[Pr(SPAM)]\") +\n    theme_bw() +\n    opts(axis.text.x = theme_blank(), axis.text.y = theme_blank())\nggsave(plot = class.plot,\n       filename = file.path(\"images\", \"03_final_classification.pdf\"),\n       height = 10,\n       width = 10)\n\nget.results <- function(bool.vector)\n{\n  results <- c(length(bool.vector[which(bool.vector == FALSE)]) / length(bool.vector),\n               length(bool.vector[which(bool.vector == TRUE)]) / length(bool.vector))\n  return(results)\n}\n\n# Save results as a 2x3 table\neasyham2.col <- get.results(subset(class.df, Type == \"EASYHAM\")$Class)\nhardham2.col <- get.results(subset(class.df, Type == \"HARDHAM\")$Class)\nspam2.col <- get.results(subset(class.df, Type == \"SPAM\")$Class)\n\nclass.res <- rbind(easyham2.col, hardham2.col, spam2.col)\ncolnames(class.res) <- c(\"NOT SPAM\", \"SPAM\")\nprint(class.res)\n\n# Save the training data for use in Chapter 4\nwrite.csv(spam.df, file.path(\"data\", \"spam_df.csv\"), row.names = FALSE)\nwrite.csv(easyham.df, file.path(\"data\", \"easyham_df.csv\"), row.names = FALSE)\n",
    "created" : 1343628632159.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1136394922",
    "id" : "A656A7D5",
    "lastKnownWriteTime" : 1331999810,
    "path" : "~/Documents/RWorkSpace/Machine Learning/original/03-Classification/email_classify.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}