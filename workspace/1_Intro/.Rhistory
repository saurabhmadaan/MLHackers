hist
history()
tdf<-TweetFrame('#solar',100)
tdf<-TweetFrame('#solar',100)
# TweetFrame() - return a data frame based on a Twitter search, sorted by time of creation
# EnsurePackage -  Installs and loads package if necessary
EnsurePackage<-function(x)
{
x<-as.character(x)
if (!require(x,character.only=TRUE))
{
install.packages(pkgs=x,repos="http://cran.r-project.org")
require(x,character.only=TRUE)
}
}
# PrepareTwitter -  Loads packages for working with Twitter
PrepareTwitter<-function()
{
EnsurePackage('bitops')
EnsurePackage('RCurl')
EnsurePackage('RJSONIO')
EnsurePackage('twitteR')
}
# TweetFrame() - return a data frame based on a Twitter search, sorted by time of creation
TweetFrame<-function(searchTerm,maxTweets)
{
tweetList<-searchTwitter(searchTerm,n=maxTweets)
df<-do.call('rbind',lapply(tweetList,as.data.frame))
sorteddf<-df[order(as.integer(df$created)),]
return(sorteddf)
}
# ArrivalProbability() - Given a list of arrival times calculates delays between them using lagged
# differences, then computes a list of cumulative probabilities of arrival for sequential list
# of time increments
ArrivalProbability<-function(timesList,increment,max)
{
plist<-NULL
timeLen<-length(timesList)
if(increment>max){return(NULL)}
for(i in seq(increment,max,by=increment))
{
plist<-c(plist,(sum(as.integer(diff(timesList))<i))/timeLen)
}
return(plist)
}
# tf<-TweetFrame('oprah',500)
# pl<-ArrivalProbability(tf$created,1,40)
# plot(pl)
#of<-TweetFrame('#oprah',500)
#gf<-TweetFrame('#ladygaga',500)
#ofEventDelays<-as.integer(diff(of$created))
#gfEventDelays<-as.integer(diff(gf$created))
#mean(ofEventDelays)
#mean(gfEventDelays)
#sum(gfEventDelays<=43)
# [1] 320
# poisson.test(320,500)$conf.int
#sum(ofEventDelays<=43)
#[1] 82
#poisson.test(82,500)$conf.int
# no overlap between oprah and gaga conf intervals. significantly differ
PoissComp<-function(String1,String2,n)
{
tf1<-TweetFrame(String1,n)
tf2<-TweetFrame(String2,n)
v1<-diff(as.integer(tf1$created))
v2<-diff(as.integer(tf2$created))
AvgArr1<-mean(v1)
AvgArr2<-mean(v2)
TweetsBelowThreshold1<-sum(v1<=AvgArr1)
TweetsBelowThreshold2<-sum(v2<=AvgArr1) #using avg arrival of 1st dist as threshold
pt<-poisson.test(c(TweetsBelowThreshold1,TweetsBelowThreshold2),c(n,n))
return(pt)
}
tdf<-TweetFrame('#solar',100)
EnsurePackages()
PrepareTwitter()
tdf<-TweetFrame('#solar',100)
tf<-TweetFrame('#google',500)
pl<-ArrivalProbability(tf$created,1,40)
plot(pl)
tf<-TweetFrame('#yahoo',500)
pl<-ArrivalProbability(tf$created,1,40)
plot(pl)
pl<-ArrivalProbability(tf$created,1,80)
plot(pl)
pl<-ArrivalProbability(tf$created,1,100)
plot(pl)
tf<-TweetFrame('#yahoo',1000)
tf<-TweetFrame('#yahoo',1000)
tf<-TweetFrame('#yahoo',1000)
tf<-TweetFrame('#yahoo',1000)
pl<-ArrivalProbability(tf$created,1,100)
plot(pl)
pl<-ArrivalProbability(tf$created,1,1000)
pl<-ArrivalProbability(tf$created,1,1000)
pl<-ArrivalProbability(tf$created,1,200)
pl<-ArrivalProbability(tf$created,1,10)
pl<-ArrivalProbability(tf$created,2,100)
plot(pl)
pl<-ArrivalProbability(tf$created,2,500)
plot(pl)
tdf<-TweetFrame('#solar',100)
tdf$text
attach(tdf)
text
tweets
tweets<-str_replace(text,'@[a-z,A-Z]*','')
tweets<-str_replace_all(text,'@[a-z,A-Z]*','')
library(twitteR)
tweets<-str_replace_all(text,'@[a-z,A-Z]*','')
library(stringr)
tweets<-str_replace_all(text,'@[a-z,A-Z]*','')
tweets
tweets[7]
text[7]
tweets<-str_replace_all(tweets,'http://[a-z,A-Z]*','')
tweets
tweets<-str_replace_all(text,'@[a-z,A-Z]*','')
tweets<-str_replace_all(tweets,'http://[a-z,A-Z,//]*','')
tweets
tweets<-str_replace_all(tweets,'http://t.co/[a-z,A-Z,0-9]{8}','')
tweets
tweets<-str_replace_all(text,'@[a-z,A-Z]*','')
tweets<-str_replace_all(tweets,'http://t.co/[a-z,A-Z,0-9]{8}','')
tweets
ctext<-CleanTweets(text)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
ctext<-CleanTweets(text)
ctext
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
ctext<-CleanTweets(text)
ctext
head(cltext,10)
head(ctext,10)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
EnsurePackages(tm)
EnsurePackage(tm)
EnsurePackage('tm')
tc<-Corpus(VectorSource(ctext))
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
library("codetools")
tc<-tm_map(tc,tolower)
tc<-tm_map(tc,removePunctuation)
tc<-tm_map(tc,removeWords,stopwords('english'))
tmatr<-TermDocumentMatrix(tc)
tmatr
fix(tmatr)
inspect(tmatr)
EnsurePackage(wordcloud)
EnsurePackage('wordcloud')
tmatr<-as.matrix(tmatr)
View(tmatr)
sortedtmatr<-sort(rowSums(tmatr),decreasing=TRUE)
View(tmatr)
cloudFr<-data.frame(word=names(sortedtmatr),freq=sortedmatr)
cloudFr<-data.frame(word=names(sortedtmatr),freq=sortedtmatr)
fix(sortedtmatr)
fix(sortedtmatr)
wordcloud(cloudFr$word,cloudFr$freq)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
help(rowSums)
fix(sortedtmatr)
View(tmatr)
fix(sortedtmatr)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
fix(sortedtmatr)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
View(cloudFr)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
wordcloud(cloudFrame$word,cloudFrame$freq)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
GenerateCloud('#manmohan')
GenWordCloud('#manmohan')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
GenWordCloud('#manmohan')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
GenWordCloud('#manmohan')
detach(cloudFrame)
detach('cloudFrame')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
GenWordCloud('#manmohan')
fix(GenWordCloud)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
tdm<-GenWordCloud('#manmohan')
tdm
fix(tdm)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
tf<-GenWordCloud('#manmohan')
tf
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
tf<-GenWordCloud('#manmohan')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
tf<-GenWordCloud('#manmohan')
tf<-GenWordCloud('#modi')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
tf<-GenWordCloud('#modi')
tf<-GenWordCloud('#modi',500)
tf<-GenWordCloud('#manmohan',500)
tf<-GenWordCloud('#modi',500)
warnings()
warnings()
tf<-GenWordCloud('#modi',500)
tf<-GenWordCloud('#modi',300)
tf<-GenWordCloud('#modi',300)
tf<-GenWordCloud('#modi',250)
tf<-GenWordCloud('#modi',250)
tf<-GenWordCloud('#modi',100)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
install.packages('gdata')
library(gdata)
testFr<-read.xls('http://www.census.gov/popest/data/state/totals/2011/tables/NST-EST2011-01.xls')
View(testFr)
summary(testFr)
testFr<-testFr[-1:-3,]
View(testFr)
testFr<-testFr[,1:5]
View(testFr)
testFr<-testFr[-58:-62,]
View(testFr)
testFr$region<-testFr[,1]
View(testFr)
testFr<-testFr[,-1]
View(testFr)
testFr$region<-str_replce(testFr$region,'\.','')
testFr$region<-str_replace(testFr$region,'\.','')
testFr$region<-str_replace(testFr$region,'\\.','')
View(testFr)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
testFr$April10<-Numberize(testFr$X)
testFr$April10Base<-Numberize(testFr$X)
testFr$April10Census<-Numberize(testFr$X)
View(testFr)
testFr<-testFr[,-6:-8]
View(testFr)
testFr$April10Census<-Numberize(testFr$X)
testFr$April10Base<-Numberize(testFr$X.1)
testFr$July10Base<-Numberize(testFr$X.2)
testFr$July10Census<-Numberize(testFr$Base)
testFr$July10Census<-testFr$Base
testFr$July10Census<-testFr$July10Base
testFr$July10Base<-Numberize(testFr$X.3)
View(testFr)
testFr$July10Pop<-Numberize(testFr$X.2)
testFr$July11Pop<-Numberize(testFr$X.3)
View(testFr)
View(tmatr)
testFr<-subset(testFr,select=-c(testFr$July10Census,testFr$July10Base))
View(testFr)
View(testFr)
testFr<-testFr[-c(testFr$July10Census,testFr$July10Base)]
View(testFr)
testFr<-testFr[-c(July10Census,July10Base)]
testFr<-testFr[-c('July10Census','July10Base')]
testFr<-testFr[-testFr$July10Census]
View(testFr)
testFr[-testFr$July10Census]
testFr[-testFr$July10Census]
testFr[-testFr$July10Census]
testFr[-testFr$July10Census]
testFr[July10Census]
testFr[testFr$July10Census]
testFr
testFr$July10Census
testFr[$July10Census]
testFr[July10Census]
testFr['July10Census']
testFr[-'July10Census']
testFr['July10Census']
testFr['July10Census','July10Base']
testFr['July10Census','July10Base']
testFr['July10Census']
testFr['July10Base']
testFr[c('July10Base')]
testFr[c('July10Base','July10Base')]
testFr[-c('July10Base','July10Base')]
subset(testFr, select = -c('July10Base','July10Base'))
subset(testFr, select = -c(July10Base,July10Base))
subset(testFr, select = -c(July10Base,July10Census))
testFr<-subset(testFr, select = -c(July10Base,July10Census))
View(testFr)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
library(RMySQL)
con <-dbConnect(dbDriver('MySQL'),dbname='test')
dbListTables(con)
dbWriteTable(con,'census',testFr,overwrite=TRUE)
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
dbListTables(con)
dbGetQuery(con,'SELECT region,july11pop FROM census where july11pop<1000000')
install.packages(RJSONIO)
install.packages('RJSONIO')
install.packages('itertools')
install.packages('digest')
install.packages('rJava')
install.packages('rcurl')
install.packages('RCurl')
source('~/Documents/RWorkSpace/Twitter/1_PrepareTwitter.R')
load("~/Documents/RWorkSpace/Machine Learning/Machine Learning.Rproj")
good.row.nums<-ifelse(nchar(ufo$DateOccurred)!=8 | nchar(ufo$DateReported)!=8,FALSE,TRUE)
ufo<-read.delim('data/ufo/ufo_awesome.tsv',sep='\t',stringsAsFactors=FALSE,header=FALSE,na.strings='')
setwd("/Users/saurabh/Documents/RWorkSpace/Machine Learning/workspace/1_Intro")
ufo<-read.delim('data/ufo/ufo_awesome.tsv',sep='\t',stringsAsFactors=FALSE,header=FALSE,na.strings='')
good.row.nums<-ifelse(nchar(ufo$DateOccurred)!=8 | nchar(ufo$DateReported)!=8,FALSE,TRUE)
length(which(!good.row.nums))# how many rows are not good
names(ufo)<-c('DateOccurred','DateReported','Location','ShortDescription','Duration','LongDescription')
good.row.nums<-ifelse(nchar(ufo$DateOccurred)!=8 | nchar(ufo$DateReported)!=8,FALSE,TRUE)
length(which(!good.row.nums))# how many rows are not good
ufo<-ufo[good.rows.nums,] # keep only the good rows
ufo<-ufo[good.row.nums,] # keep only the good rows
ufo$DateOccurred<as.Date(ufo$DateOccurred,format='%Y%m%d'
)
ufo$DateOccurred<as.Date(ufo$DateOccurred,format='%Y%m%d')
ufo$DateOccurred<as.Date(as.character(ufo$DateOccurred),format='%Y%m%d')
ufo$DateOccurred<as.Date(as.character(ufo$DateOccurred,format="%Y%m%d")
)
ufo$DateOccurred<as.Date(ufo$DateOccurred,format="%Y%m%d")
source('~/Documents/RWorkSpace/Machine Learning/workspace/1_Intro/1_intro.R')
source('~/Documents/RWorkSpace/Machine Learning/workspace/1_Intro/1_intro.R')
